{
  "name": "Enhanced Augmented Reality Head-up Display",
  "tagline": "",
  "body": "# ABSTRACT\r\nThe purpose of this project was to attempt to improve the use of augmented reality systems to detect items of interest to individuals who are operating a vehicle on a public road. The intelligent system utilizes open CV image recognition techniques to correctly identify objects and display data in real time to a user.\r\n\r\n***\r\n\r\n# PROBLEM DESCRIPTION\r\nThroughout the world there are countless numbers of driving related accidents and fatalities on a daily basis. A study conducted by the US Department of Transportation has shown that drivers using a head up display (HUD) rather than a Head Down Display (HDD) for driving assistance, results in few collisions on the road.\r\n\r\n![Charissis, V. Enhancing human responses through augmented reality Head-Up Display in vehicular environment. in 2014 11th International Conference & Expo on Emerging Technologies for a Smarter World (CEWIT), (Melville, New York, 2014), IEEE\r\n](https://github.com/joekill/joekill.github.io/blob/master/HDDvsHUD.jpg?raw=true)\r\n\r\nThe benefits accompanied by the creation of an efficient augmented reality head up display system would be tremendous. Computer vision is essential to solving this problem and there is a lot of work to be covered before a sufficient system is created. In order to solve this issue, the enhanced system uses various Computer Vision techniques including grey scale image processing, straight line searching, and a few limiting opportunities to decrease the number of false positive finds.\r\n\r\n***\r\n\r\n# METHODS\r\nTo achieve improvements in the system, three main changes were made that improved the accuracy and efficiency of the program.\r\n\r\n1. Removal of any lines that were almost vertical (70 degrees or more) as well as the removal of lines that were completely horizontal to the vehicle (10 degrees or less)\r\n\r\n2. Reduction in the scope that the video was gathering data from. This was done to avoid conducting calculations on pieces of the image that weren't of interest, the idea being that the only useful parts of the video feed are items that are within the cars main field of view, avoid items in the sky or attached to the car.\r\n\r\n3. Adjustments to the grey scale of an image so that unnecessary light and objects could be filtered out and avoided during processing\r\n\r\n***\r\n\r\n# RESULTS\r\nThese three changes made a world of difference in the output from the system as illustrated by figure 2 and 3 below:\r\n\r\n![Before Changes](https://github.com/joekill/joekill.github.io/blob/master/BeforeChanges.png?raw=true)\r\n\r\n![After Changes](https://github.com/joekill/joekill.github.io/blob/master/AfterChanges.png?raw=true)\r\n\r\nAs seen in the graph below, the accuracy of the system was improved greatly by cutting back the number of unnecessary lines that were discovered and outlined by the algorithm.\r\n\r\n![Day Time Results](https://github.com/joekill/joekill.github.io/blob/master/DayTimeResults.png?raw=true)\r\n\r\nSurprisingly though, almost no difference was made with the nighttime driving, this as due to the fact that there is far less extra noise for the algorithm to sift through when processing nighttime footage. This is because the video feed can see only items illuminated by the vehicles lights.\r\n\r\n![Night Time Results](https://github.com/joekill/joekill.github.io/blob/master/NightTimeResults.png?raw=true)\r\n\r\n# CONCLUSION\r\nThrough the use of the different methods discussed in this document, changes were made to the system that showed very clear and defined improvements in accuracy. Image processing and computer vision techniques can be refined and improved in order to accurately and efficiently display real time driving data to a user.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}